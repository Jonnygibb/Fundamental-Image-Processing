@incollection{Gayathri2021,
  doi = {10.1007/978-981-16-2674-6_14},
  url = {https://doi.org/10.1007/978-981-16-2674-6_14},
  year = {2021},
  month = aug,
  publisher = {Springer Singapore},
  pages = {179--185},
  author = {S. Gayathri and D. K. Aarthy},
  title = {Computer-Aided Detection of Malignant Mass in Mammogram Using U-Net Architecture},
  booktitle = {Advances in Intelligent Systems and Computing}
}
@article{DBLP:journals/corr/IsolaZZE16,
  author    = {Phillip Isola and
               Jun{-}Yan Zhu and
               Tinghui Zhou and
               Alexei A. Efros},
  title     = {Image-to-Image Translation with Conditional Adversarial Networks},
  journal   = {CoRR},
  volume    = {abs/1611.07004},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.07004},
  eprinttype = {arXiv},
  eprint    = {1611.07004},
  timestamp = {Mon, 13 Aug 2018 16:49:05 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/IsolaZZE16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{DBLP:journals/corr/abs-1803-07422,
  author    = {Ugur Demir and
               G{\"{o}}zde B. {\"{U}}nal},
  title     = {Patch-Based Image Inpainting with Generative Adversarial Networks},
  journal   = {CoRR},
  volume    = {abs/1803.07422},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.07422},
  eprinttype = {arXiv},
  eprint    = {1803.07422},
  timestamp = {Mon, 13 Aug 2018 16:49:01 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1803-07422.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Ali_2022,
	doi = {10.1109/tcsii.2022.3181132},
	url = {https://doi.org/10.1109%2Ftcsii.2022.3181132},
	year = 2022,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	pages = {1--1},
	author = {Owais Ali and Hazrat Ali and Syed Ayaz Ali Shah and Aamir Shahzad},
	title = {Implementation of a Modified U-Net for Medical Image Segmentation on Edge Devices},
	journal = {{IEEE} Transactions on Circuits and Systems {II}: Express Briefs}
}
@Inbook{Ketkar2017,
author="Ketkar, Nikhil",
title="Feed Forward Neural Networks",
bookTitle="Deep Learning with Python: A Hands-on Introduction",
year="2017",
publisher="Apress",
address="Berkeley, CA",
pages="17--33",
abstract="In this chapter we will cover some key concepts around feedforward neural networks.",
isbn="978-1-4842-2766-4",
doi="10.1007/978-1-4842-2766-4_3",
url="https://doi.org/10.1007/978-1-4842-2766-4_3"
}
@Inbook{Michelucci2019,
author="Michelucci, Umberto",
title="Cost Functions and Style Transfer",
bookTitle="Advanced Applied Deep Learning : Convolutional Neural Networks and Object Detection",
year="2019",
publisher="Apress",
address="Berkeley, CA",
pages="161--193",
abstract="In this chapter we will look in more depth at the role of the cost function in neural network models. In particular, we will discuss the MSE (mean square error) and the cross-entropy and discuss their origin and their interpretation. We will look at why we can use them to solve problems and how the MSE can be interpreted in a statistical sense, as well as how cross-entropy is related to information theory. Then, to give you an example of a much more advanced use of special loss functions, we will learn how to do neural style transfer, where we will discuss a neural network to paint in the style of famous painters.",
isbn="978-1-4842-4976-5",
doi="10.1007/978-1-4842-4976-5_5",
url="https://doi.org/10.1007/978-1-4842-4976-5_5"
}
@InProceedings{10.1007/978-3-030-68449-5_36,
author="Sutanto, Arief Rachman
and Kang, Dae-Ki",
editor="Singh, Madhusudan
and Kang, Dae-Ki
and Lee, Jong-Ha
and Tiwary, Uma Shanker
and Singh, Dhananjay
and Chung, Wan-Young",
title="A Novel Diminish Smooth L1 Loss Model with Generative Adversarial Network",
booktitle="Intelligent Human Computer Interaction",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="361--368",
abstract="The training process of GAN can be regarded as a process in which the generation network and the identification network play against each other and finally reach a state where it cannot be further improved if the opponent does not change. At the same time, the start of the gradient descent method will choose a direction to reduce the defined loss. The loss function plays a key role in the performance of the model. Choosing the right loss function can help your model learn how to focus on the correct set of features in the data to achieve optimal and faster convergence. In this work, we propose a novel loss function scheme, namely, Diminish Smooth L1 loss. We improve a robust L1 loss called Smooth L1 loss by lowering the threshold so that the network can converge to a lower minimum. From our experimental results on several benchmark data, we found that our algorithm often outperforms the previous approaches.",
isbn="978-3-030-68449-5"
}
@misc{https://doi.org/10.48550/arxiv.2003.11596,
  doi = {10.48550/ARXIV.2003.11596},
  
  url = {https://arxiv.org/abs/2003.11596},
  
  author = {Afifi, Mahmoud and Derpanis, Konstantinos G. and Ommer, Björn and Brown, Michael S.},
  
  keywords = {Image and Video Processing (eess.IV), Computer Vision and Pattern Recognition (cs.CV), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Learning Multi-Scale Photo Exposure Correction},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@misc{https://doi.org/10.48550/arxiv.1511.06434,
  doi = {10.48550/ARXIV.1511.06434},
  
  url = {https://arxiv.org/abs/1511.06434},
  
  author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
  
  keywords = {Machine Learning (cs.LG), Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


